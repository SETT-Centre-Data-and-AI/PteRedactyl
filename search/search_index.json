{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Pteredactyl Documentation"},{"location":"#pteredactyl_python_module_gradio_webapp_api","title":"Pteredactyl Python Module, Gradio Webapp, API","text":"<ul> <li> <p>Authors: Matt Stammers\ud83e\uddea, Cai Davis\ud83e\udd7c and Michael George\ud83e\ude7a</p> </li> <li> <p>Version 1. 29/06/2024</p> </li> </ul> <p>Clinical patient identifiable information (cPII) presents a significant challenge in natural language processing (NLP) that has yet to be fully resolved but significant progress is being made [1,2].</p> <p>This is why we created Pteredactyl - a python module to help with redaction of clinical free text.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Python Module: Easily integrate Pteredactyl into your projects to redact cPII from text.</li> <li>Gradio Web App: User-friendly web interface for redaction tasks.</li> <li>Dockerised API Deployment: Deployable API for seamless integration into other systems.</li> </ul>"},{"location":"#quick_links","title":"Quick Links","text":"<p>If you want to start quickly with the python module you can do so here:</p> <ul> <li>Quickstart: Get started with Pteredactyl quickly. \ud83d\udc31\u200d\ud83c\udfcd</li> </ul> <p>For access to the live app:</p> <ul> <li>Live App To see the live app. \ud83e\udd17</li> </ul> <p>If you just want to deploy the webapp/api you can quickly do that here:</p> <ul> <li>Webapp/API Deployment: Access and use the Gradio Webapp and API. \u2728</li> </ul> <p>If you want to redact some dataframes you can find out about that here:</p> <ul> <li>DataFrame Redaction: Redacting Dataframes. \ud83d\udc31\u200d\ud83d\udc64</li> </ul> <p>Docs Version</p>"},{"location":"abstract/","title":"Abstract","text":""},{"location":"abstract/#background","title":"Background","text":"<p>We introduce a concentrated validation battery to the open-source OHDSI community, a Python module for cPII redaction on free text, and a web application that compares various models against the battery. This setup, which allows simultaneous production API deployment using  Gradio, is remarkably efficient and can operate on a single CPU core.</p>"},{"location":"abstract/#methods","title":"Methods:","text":"<p>We evaluated three open-source models from Huggingface: Stanford Base De-Identifier, Deberta PII, and Nikhilrk De-Identify using our Clinical_PII_Redaction_Test dataset. The text was tokenised, and all entities such as [PERSON], [ID], and [LOCATION] were tagged in the gold standard. Each model redacted cPII from clinical texts, and outputs were compared to the gold standard template to calculate the confusion matrix, accuracy, precision, recall, and F1 score.</p>"},{"location":"abstract/#results","title":"Results","text":"<p>The full results of the tool are given below in Table 1 below.</p> Metric Stanford Base De-Identifier Deberta PII Nikhilrk De-Identify Accuracy 0.98 0.85 0.68 Precision 0.91 0.93 0.28 Recall 0.94 0.16 0.49 F1 Score 0.93 0.28 0.36 <p>Table 1: Summary of Model Performance Metrics</p>"},{"location":"abstract/#strengths","title":"Strengths","text":"<ul> <li> <p>The test benchmark Clinical_PII_Redaction_Test intentionally exploits commonly observed weaknesses in NLP cPII token masking systems such as clinician/patient/diagnosis name similarity and commonly observed ID/username and location/postcode issues.</p> </li> <li> <p>The Stanford De-Identifier Base Model[1] is 99% accurate on our test set of radiology reports and achieves an F1 score of 93% on our challenging open-source benchmark. The others models are really to demonstrate the potential of Pteredactyl to deploy any transfomer model.</p> </li> <li> <p>We have submitted the code to OHDSI as an abstract and aim strongly to incorporate this into a wider open-source effort to solve intractable clinical informatics problems.</p> </li> </ul>"},{"location":"abstract/#limitations","title":"Limitations","text":"<ul> <li> <p>The tool was not designed initially to redact clinic letters as it was developed primarily on radiology reports in the US. We have made some augmentations to cover elements like postcodes using checksums but these might not always work. The same is true of NHS numbers as illustrated above.</p> </li> <li> <p>It may overly aggressively redact text because it was built as a research tool where precision is prized &gt; recall. However, in our experience this is uncommon enough that it is still very useful.</p> </li> <li> <p>This is very much a research tool and should not be relied upon as a catch-all in any production-type capacity. The app makes the limitations very transparently obvious via the attached confusion matrix.</p> </li> </ul>"},{"location":"abstract/#conclusion","title":"Conclusion","text":"<p>The validation cohort introduced in this study proves to be a highly effective tool for discriminating the performance of open-source cPII redaction models. Intentionally exploiting common weaknesses in cNLP token masking systems offers a more rigorous cPII benchmark than many larger datasets provide.</p> <p>We invite the open-source community to collaborate to improve the present results and enhance the robustness of cPII redaction methods by building on the work we have begun here.</p>"},{"location":"abstract/#references","title":"References:","text":"<ol> <li>Chambon PJ, Wu C, Steinkamp JM, Adleberg J, Cook TS, Langlotz CP. Automated deidentification of radiology reports combining transformer and \u201chide in plain sight\u201d rule-based methods. J Am Med Inform Assoc. 2023 Feb 1;30(2):318\u201328.</li> <li>Kotevski DP, Smee RI, Field M, Nemes YN, Broadley K, Vajdic CM. Evaluation of an automated Presidio anonymisation model for unstructured radiation oncology electronic medical records in an Australian setting. Int J Med Inf. 2022 Dec 1;168:104880.</li> </ol>"},{"location":"version/","title":"Version","text":""},{"location":"version/#version","title":"version","text":"<p>1.0.0</p>"},{"location":"Python_Module/anonymising_dataframes/","title":"Anonymising DataFrames","text":"<p>The <code>anonymise_df()</code> function is designed to anonymise sensitive information in a pandas DataFrame. This function can handle Named Entity Recognition (NER) and regex-based entity recognition to redact information such as names, addresses, and other personal identifiers. It can act on a single column or multiple, and redact inplace or by returning a new DataFrame/column</p>"},{"location":"Python_Module/anonymising_dataframes/#parameters","title":"Parameters","text":"<ul> <li><code>df</code>: The DataFrame containing the text to anonymise.</li> <li><code>column</code>: The name or list of names of the column(s) to anonymise.</li> <li><code>analyser</code>: An optional AnalyzerEngine instance. If not provided, a new analyser will be created.</li> <li><code>entities</code>: A list of entities to anonymise using the NER model.</li> <li><code>regex_entities</code>: A list of regex patterns or custom recognisers to identify and anonymise.</li> <li><code>highlight</code>: If <code>True</code>, anonymised parts are highlighted.</li> <li><code>replacement_lists</code>: A dictionary for hide-in-plain-sight redaction containing replacement values per entity type.</li> <li><code>inplace</code>: If <code>True</code>, the original DataFrame is modified; otherwise, a copy is returned.</li> <li><code>col_inplace</code>: If <code>True</code>, the original column is replaced with the redacted version.</li> </ul>"},{"location":"Python_Module/anonymising_dataframes/#basic_example","title":"Basic Example","text":"<p>Here's a basic example of anonymising a DataFrame column:</p> <pre><code>import pandas as pd\nimport pteredactyl as pt\n\nanalyser = pt.create_analyser()\n\n# Create a DataFrame with sample data\ndf = pd.DataFrame({\n    'text': [\n        \"John Doe's number is 07111 293892.\",\n        \"Jane Smith's lives at 123 Shirley Road.\"\n    ]\n})\n\n# Anonymise the 'text' column\nanonymised_df = pt.anonymise_df(\n    df=df,\n    column='text',\n    analyser=analyser,\n    entities=['PERSON', 'PHONE_NUMBER', 'LOCATION'],\n    inplace=False\n)\n\n# Print the result\nprint(anonymised_df)\n</code></pre> <pre><code>                                      text                       text_redacted\n0       John Doe's number is 07111 293892.  &lt;PERSON&gt;'s number is 07111 293892.\n1  Jane Smith's lives at 123 Shirley Road.     &lt;PERSON&gt;'s lives at &lt;LOCATION&gt;.\n</code></pre>"},{"location":"Python_Module/developing-contributing/","title":"Developing/Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"Python_Module/developing-contributing/#types_of_contributions","title":"Types of Contributions","text":""},{"location":"Python_Module/developing-contributing/#report_bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/SETT-Centre-Data-and-AI/PteRedactyl/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"Python_Module/developing-contributing/#fix_bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"Python_Module/developing-contributing/#implement_features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"Python_Module/developing-contributing/#submit_feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/SETT-Centre-Data-and-AI/PteRedactyl/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> </ul>"},{"location":"Python_Module/developing-contributing/#get_started","title":"Get Started","text":"<p>Ready to contribute? Here's how to set up <code>pteredactyl</code> for local development.</p> <ol> <li>Fork the <code>pteredactyl</code> repo on GitHub.</li> <li> <p>Clone your fork locally:</p> <p><code>bash git clone git@github.com:your_name_here/pteredactyl.git</code></p> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have poetry installed, this is how you set up your fork for local development:</p> <p><code>bash poetry shell poetry install</code></p> </li> <li> <p>Create a branch for local development::</p> <p><code>bash git checkout -b name-of-your-bugfix-or-feature</code></p> </li> </ol> <p>Now you can make your changes locally.</p> <ol> <li> <p>When you're done making changes, check that your changes pass the pre-commit hooks. To set this up call the following from your git repository:</p> <p><code>bash pre-commit install</code></p> </li> <li> <p>Commit your changes and push your branch to GitHub::</p> <p><code>bash git add . git commit -m \"Your detailed description of your changes.\" git push</code> or <code>bash git add . cz commit git push</code></p> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"Python_Module/developing-contributing/#pull_request_guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.rst.</li> <li>The pull request should work for Python &gt;3.10</li> </ol>"},{"location":"Python_Module/developing-contributing/#tips","title":"Tips","text":"<p>To run a subset of tests navigate to the tests folder and call a test::</p> <pre><code>python test_api.py\n</code></pre>"},{"location":"Python_Module/developing-contributing/#deploying","title":"Deploying","text":"<p>To build a docker image deployment with the web-app / API version you can use the following in your command line:</p> <pre><code>docker build -t pteredactyl:latest .\ndocker run -d -p 7860:7860 --name pteredactyl-app pteredactyl:latest\n</code></pre>"},{"location":"Python_Module/examining_results/","title":"Examining Results","text":"<p>Instead of anonymising, we can instead check the results of analysis by using the <code>analyse()</code> function.</p> <pre><code>import pteredactyl as pt\n\ntext = \"The patient's name is Steven Johnson. His NHS Number is 0123456789 and postcode is SO16 2HQ. He has been diagnosed with Stevens Johnson Syndrome\"\nanalyser = pt.create_analyser()\nanalysis = pt.analyse(text=text, analyser=analyser)\nfor result in analysis:\n    print(result)\n</code></pre>"},{"location":"Python_Module/landing/","title":"Introduction","text":"<p>PteRedactyl is a redaction package for personally identifiable information (PII) in text, that combines NER models with regex matching to identify and mask sensitive information. Custom transformers-based NER models can be swapped in,</p> <p>This guide will cover usage of PteRedactyl's main functions: <code>create_analyser</code>, <code>analyse</code>, <code>anonymise</code> and <code>anonymise_df</code>:</p> <ul> <li><code>create_analyser()</code>: Creates a presidio AnalyserEngine that can be reused across high-level functions</li> <li><code>analyse()</code>: Analyses a string for PII, returning a list of recognised NER or regex-based results with scores</li> <li><code>anonymise()</code>: Analyses and anonymises text, replacing PII with placeholders or hide-in-plain-sight (HIPS) replacements</li> <li><code>anonymise_df()</code>: As above, but by looping over a given column (or columns) in a DataFrame</li> </ul>"},{"location":"Python_Module/mkdocstrings/","title":"Mkdocstrings","text":""},{"location":"Python_Module/mkdocstrings/#overview","title":"Overview","text":"<p>The <code>pteredactyl</code> module provides various functions and classes for data anonymization and redaction.</p>"},{"location":"Python_Module/mkdocstrings/#defaults","title":"Defaults","text":""},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.defaults.change_model","title":"<code>change_model(new_model)</code>","text":"<p>Change the default NER model.</p>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.defaults.change_model--parameters","title":"Parameters","text":"<p>new_model : str     The new model path to be set as the default NER model.</p>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.defaults.change_model--returns","title":"Returns","text":"<p>None</p> Source code in <code>pteredactyl\\pteredactyl\\defaults.py</code> <pre><code>def change_model(new_model: str) -&gt; None:\n    \"\"\"\n    Change the default NER model.\n\n    Parameters\n    ----------\n    new_model : str\n        The new model path to be set as the default NER model.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    global DEFAULT_NER_MODEL\n    DEFAULT_NER_MODEL = new_model\n    print(f\"DEFAULT_NER_MODEL changed to: {DEFAULT_NER_MODEL}\")\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.defaults.show_defaults","title":"<code>show_defaults()</code>","text":"<p>Print the default values used by pteredactyl.</p> <p>This function shows the default values for the following variables: - DEFAULT_NER_MODEL (for model_path) - DEFAULT_SPACY_MODEL (for spacy_model) - DEFAULT_ENTITIES (for entities) - DEFAULT_REGEX_ENTITIES (for regex_entities)</p>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.defaults.show_defaults--returns","title":"Returns","text":"<p>None</p> Source code in <code>pteredactyl\\pteredactyl\\defaults.py</code> <pre><code>def show_defaults() -&gt; None:\n    \"\"\"\n    Print the default values used by pteredactyl.\n\n    This function shows the default values for the following variables:\n    - DEFAULT_NER_MODEL (for model_path)\n    - DEFAULT_SPACY_MODEL (for spacy_model)\n    - DEFAULT_ENTITIES (for entities)\n    - DEFAULT_REGEX_ENTITIES (for regex_entities)\n\n    Returns\n    -------\n    None\n    \"\"\"\n    print(\"PteRedactyl Defaults\")\n    print(\"--------------------\")\n    print(f\"DEFAULT_NER_MODEL:      {DEFAULT_NER_MODEL}\")\n    print(f\"DEFAULT_SPACY_MODEL:    {DEFAULT_SPACY_MODEL}\")\n    print(f\"DEFAULT_ENTITIES:       {DEFAULT_ENTITIES}\")\n    print(f\"DEFAULT_REGEX_ENTITIES: {DEFAULT_REGEX_ENTITIES}\")\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#exceptions","title":"Exceptions","text":""},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.exceptions.MissingRegexRecogniserError","title":"<code>MissingRegexRecogniserError</code>","text":"<p>               Bases: <code>KeyError</code></p> <p>Exception raised when a regex recogniser is requested but not found in the supported regex_entities list.</p> <p>Attributes:</p> Name Type Description <code>message</code> <code>str</code> <p>The error message.</p> Source code in <code>pteredactyl\\pteredactyl\\exceptions.py</code> <pre><code>class MissingRegexRecogniserError(KeyError):\n    \"\"\"\n    Exception raised when a regex recogniser is requested but not found in the supported regex_entities list.\n\n    Attributes:\n        message (str): The error message.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str = \"No regex settings could detected in pteredactyl.regex_entities\",\n    ):\n        super().__init__(message)\n        self.message = message\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#redactor","title":"Redactor","text":"<p>This module provides functionalities for text redaction.</p> <p>Create an analyser engine with a Transformers NER model and spaCy model.</p> Source code in <code>pteredactyl\\pteredactyl\\redactor.py</code> <pre><code>def create_analyser(\n    model_path: str = None,\n    spacy_model: str = DEFAULT_SPACY_MODEL,\n    language: str = \"en\",\n    regex_entities: Sequence[str | PteredactylRecogniser] = DEFAULT_REGEX_ENTITIES,\n) -&gt; AnalyzerEngine:\n    \"\"\"\n    Create an analyser engine with a Transformers NER model and spaCy model.\n    \"\"\"\n    if not model_path:\n        raise ValueError(\"No model path provided for NER model.\")\n\n    print(f\"Using model path: {model_path}\")\n\n    if regex_entities:\n        regex_entities = build_regex_entity_recogniser_list(\n            regex_entities=regex_entities\n        )\n\n    load_spacy_model(spacy_model)\n\n    transformers_recogniser = load_transformers_recognizer(model_path)\n\n    nlp_configuration = load_nlp_configuration(\n        language=language, spacy_model=spacy_model\n    )\n\n    registry = load_registry(\n        transformers_recogniser=transformers_recogniser, regex_entities=regex_entities\n    )\n\n    nlp_engine = load_nlp_engine(\n        presidio_logger=presidio_logger, nlp_configuration=nlp_configuration\n    )\n\n    analyser = AnalyzerEngine(nlp_engine=nlp_engine, registry=registry)\n\n    return analyser\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#redactor_analyser","title":"Redactor Analyser","text":"<p>Analyses text using the provided NER models and entities, and returns list of those identified. It is recommended to first create an analyser and feed this in to be reused with:     &gt;&gt;&gt; analyser = create_analyser()     &gt;&gt;&gt; analyser(text=text, analyser=analyser)</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to be analyzed.</p> required <code>analyser</code> <code>AnalyzerEngine</code> <p>An instance of AnalyzerEngine. If not provided, a new analyser will be created (recommend creating first viacreate_analyser(), before feeding in).</p> <code>None</code> <code>entities</code> <code>list</code> <p>A list of entity types to analyse. If not provided, a default list will be used.</p> <code>DEFAULT_ENTITIES</code> <code>regex_entities</code> <code>list</code> <p>A list of regex entities or PteredactylRecognisers to analyse. If not provided, a default list will be used.</p> <code>DEFAULT_REGEX_ENTITIES</code> <code>model_path</code> <code>str</code> <p>The path to the model used for analysis (e.g. 'StanfordAIMI/stanford-deidentifier-base'). Used only if analyser not provided.</p> <code>None</code> <code>spacy_model</code> <code>str</code> <p>The spaCy model to use (e.g. 'en_core_web_sm'). Used only if analyser not provided.</p> <code>DEFAULT_SPACY_MODEL</code> <code>language</code> <code>str</code> <p>The language of the text to be analyzed. Defaults to \"en\". Used only if analyser not provided.</p> <code>'en'</code> <code>mask_individual_words</code> <code>bool</code> <p>If True, prevents joining of next-door entities together. (i.e. with Jane Smith, both 'Jane' and 'Smith' are identified separately if True, combined if False). Defaults to False.</p> <code>False</code> <code>text_separator</code> <code>str</code> <p>Text separator. Default is whitespace.</p> <code>' '</code> <code>rebuild_regex_recognisers</code> <code>bool</code> <p>If True, and an existing analyser is provided, the analyser's regex recognisers will be rebuilt before execution.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments for the analyzer.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>list</code> <code>list[RecognizerResult]</code> <p>The analysis results.</p> Example <p>from pteredactyl.redactor import analyse text = \"My name is John Doe and my NHS number is 7890123450\" results = analyse(text) print(results) [RecognizerResult(entity_type='PERSON', start=10, end=19, score=1.0),  RecognizerResult(entity_type='NHS_NUMBER', start=36, end=46, score=1.0)]</p> Source code in <code>pteredactyl\\pteredactyl\\redactor.py</code> <pre><code>def analyse(\n    text: str,\n    analyser: AnalyzerEngine | None = None,\n    entities: str | list[str] = DEFAULT_ENTITIES,\n    regex_entities: Sequence[str | PteredactylRecogniser] = DEFAULT_REGEX_ENTITIES,\n    model_path: str = None,\n    spacy_model: str = DEFAULT_SPACY_MODEL,\n    language: str = \"en\",\n    mask_individual_words: bool = False,\n    text_separator: str = \" \",\n    rebuild_regex_recognisers: bool = True,\n    **kwargs,\n) -&gt; list[RecognizerResult]:\n    \"\"\"\n    Analyses text using the provided NER models and entities, and returns list of those identified.\n    It is recommended to first create an analyser and feed this in to be reused with:\n        &gt;&gt;&gt; analyser = create_analyser()\n        &gt;&gt;&gt; analyser(text=text, analyser=analyser)\n\n    Args:\n        text (str): The text to be analyzed.\n        analyser (AnalyzerEngine, optional): An instance of AnalyzerEngine. If not provided, a new analyser will be created\n            (recommend creating first viacreate_analyser(), before feeding in).\n        entities (list, optional): A list of entity types to analyse. If not provided, a default list will be used.\n        regex_entities (list, optional): A list of regex entities or PteredactylRecognisers to analyse. If not provided, a default list will be used.\n        model_path (str): The path to the model used for analysis (e.g. 'StanfordAIMI/stanford-deidentifier-base'). Used only if analyser not provided.\n        spacy_model (str): The spaCy model to use (e.g. 'en_core_web_sm'). Used only if analyser not provided.\n        language (str): The language of the text to be analyzed. Defaults to \"en\". Used only if analyser not provided.\n        mask_individual_words (bool): If True, prevents joining of next-door entities together.\n            (i.e. with Jane Smith, both 'Jane' and 'Smith' are identified separately if True, combined if False). Defaults to False.\n        text_separator (str): Text separator. Default is whitespace.\n        rebuild_regex_recognisers (bool): If True, and an existing analyser is provided, the analyser's regex recognisers will be rebuilt before execution.\n        **kwargs: Additional keyword arguments for the analyzer.\n\n    Returns:\n        list: The analysis results.\n\n    Example:\n        &gt;&gt;&gt; from pteredactyl.redactor import analyse\n        &gt;&gt;&gt; text = \"My name is John Doe and my NHS number is 7890123450\"\n        &gt;&gt;&gt; results = analyse(text)\n        &gt;&gt;&gt; print(results)\n        [RecognizerResult(entity_type='PERSON', start=10, end=19, score=1.0),\n         RecognizerResult(entity_type='NHS_NUMBER', start=36, end=46, score=1.0)]\n    \"\"\"\n\n    # Prepare\n    entities = [entities] if isinstance(entities, str) else entities if entities else []\n    regex_entities = (\n        build_regex_entity_recogniser_list(regex_entities=regex_entities)\n        if regex_entities\n        else []\n    )\n    allowed_entities = entities\n    allowed_regex_entities = [\n        regex_entity.entity_type for regex_entity in regex_entities\n    ]\n    entities = allowed_entities + allowed_regex_entities\n\n    # Check Analyser\n    if not analyser:\n        analyser = create_analyser(\n            model_path=model_path,\n            spacy_model=spacy_model,\n            language=language,\n            regex_entities=regex_entities,\n        )\n    else:\n        if rebuild_regex_recognisers:\n            rebuild_analyser_regex_recognisers(\n                analyser=analyser, regex_entities=regex_entities\n            )\n\n    # Analyse\n    initial_results = analyser.analyze(\n        text, language=language, entities=entities, **kwargs\n    )\n\n    if mask_individual_words:\n        initial_results = split_results_into_individual_words(\n            text=text, results=initial_results, text_separator=text_separator\n        )\n\n    results = return_allowed_results(\n        initial_results=initial_results,\n        allowed_entities=allowed_entities,\n        allowed_regex_entities=allowed_regex_entities,\n    )\n\n    results.sort(key=lambda x: x.start)\n\n    return results\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#redactor_anonymiser","title":"Redactor Anonymiser","text":"<p>Anonymises the given text by replacing specified entities by NER, and and regex entities by REGEX. Regex entities take priority and are analysed first. It is recommended to first create an analyser and feed this in to be reused.</p> <p>Args: text (str): The text to be anonymized. analyser (AnalyzerEngine, optional): An instance of AnalyzerEngine. If not provided, a new analyser will be created. entities (list, optional): A list of entity types to anonymize. If not provided, a default list will be used. regex_entities (list, optional): A list of regex entities or PteredactylRecognisers to analyse. If not provided, a default list will be used. highlight (bool): If True, highlights the anonymized parts in the text. replacement_lists: (dict, optional): A dictionary with entity types as keys and lists of replacement values for hide-in-plain-sight redaction. model_path (str): The path to the model used for analysis. Used only if analyser not provided. spacy_model (str): The spaCy model to use. Used only if analyser not provided. language (str): The language of the text to be analyzed. Defaults to \"en\". Used only if analyser not provided. mask_individual_words (bool): If True, prevents joining of next-door entities together.         (i.e. Jane Smith becomes   if True, or  if False). Defaults to False. text_separator (str): Text separator. Default is whitespace. rebuild_regex_recognisers (bool): If True, and an existing analyser is provided, the analyser's regex recognisers will be rebuilt before execution. **kwargs: Additional keyword arguments for analyse. <p>Returns: str: The anonymized text.</p> Example <p>analyser = create_analyser() text = '''     Patient Name: John Doe     NHS Number: 7890123450     Address: AB1 0CD     Date: January 1, 2022     Diagnostic Findings:     The CT scan of the patient's chest revealed a mass in the right upper lobe of the lungs.     The mass is suspected to be malignant and is likely to be a tumor.     Further diagnostic tests, such as biopsy or CT scan of the mass, may be required to confirm the diagnosis.     Recommendations:     The patient is advised to consult with a medical specialist for a thorough evaluation of the mass.     If the tumor is malignant, further treatment, such as surgery or radiotherapy, may be recommended.     '''</p> <p>results = anonymise(text, analyser=analyser, entities=[\"DATE_TIME\", \"PERSON\"], regex_recognizers=[\"POSTCODE\", \"NHS_NUMBER\"]) print(results)</p> <pre><code>Patient Name: &lt;PERSON&gt;\nNHS Number: &lt;NHS_NUMBER&gt;\nAddress: &lt;POSTCODE&gt;\nDate: &lt;DATE_TIME&gt;\nDiagnostic Findings:\nThe CT scan of the patient's chest revealed a mass in the right upper lobe of the lungs.\nThe mass is suspected to be malignant and is likely to be a tumor.\nFurther diagnostic tests, such as biopsy or CT scan of the mass, may be required to confirm the diagnosis.\nRecommendations:\nThe patient is advised to consult with a medical specialist for a thorough evaluation of the mass.\nIf the tumor is malignant, further treatment, such as surgery or radiotherapy, may be recommended.\n</code></pre> Source code in <code>pteredactyl\\pteredactyl\\redactor.py</code> <pre><code>def anonymise(\n    text: str,\n    analyser: AnalyzerEngine | None = None,\n    entities: str | list[str] = DEFAULT_ENTITIES,\n    regex_entities: Sequence[str | PteredactylRecogniser] = DEFAULT_REGEX_ENTITIES,\n    highlight: bool = False,\n    replacement_lists: dict | None = None,\n    model_path: str = None,\n    spacy_model: str = DEFAULT_SPACY_MODEL,\n    language: str = \"en\",\n    mask_individual_words: bool = False,\n    text_separator: str = \" \",\n    rebuild_regex_recognisers: bool = True,\n    **kwargs,\n) -&gt; str:\n    \"\"\"\n    Anonymises the given text by replacing specified entities by NER, and and regex entities by REGEX. Regex entities take priority and are analysed first.\n    It is recommended to first create an analyser and feed this in to be reused.\n\n    Args:\n    text (str): The text to be anonymized.\n    analyser (AnalyzerEngine, optional): An instance of AnalyzerEngine. If not provided, a new analyser will be created.\n    entities (list, optional): A list of entity types to anonymize. If not provided, a default list will be used.\n    regex_entities (list, optional): A list of regex entities or PteredactylRecognisers to analyse. If not provided, a default list will be used.\n    highlight (bool): If True, highlights the anonymized parts in the text.\n    replacement_lists: (dict, optional): A dictionary with entity types as keys and lists of replacement values for hide-in-plain-sight redaction.\n    model_path (str): The path to the model used for analysis. Used only if analyser not provided.\n    spacy_model (str): The spaCy model to use. Used only if analyser not provided.\n    language (str): The language of the text to be analyzed. Defaults to \"en\". Used only if analyser not provided.\n    mask_individual_words (bool): If True, prevents joining of next-door entities together.\n            (i.e. Jane Smith becomes &lt;PERSON&gt; &lt;PERSON&gt; if True, or &lt;PERSON&gt; if False). Defaults to False.\n    text_separator (str): Text separator. Default is whitespace.\n    rebuild_regex_recognisers (bool): If True, and an existing analyser is provided, the analyser's regex recognisers will be rebuilt before execution.\n    **kwargs: Additional keyword arguments for analyse.\n\n    Returns:\n    str: The anonymized text.\n\n    Example:\n        &gt;&gt;&gt; analyser = create_analyser()\n        &gt;&gt;&gt; text = '''\n            Patient Name: John Doe\n            NHS Number: 7890123450\n            Address: AB1 0CD\n            Date: January 1, 2022\n            Diagnostic Findings:\n            The CT scan of the patient's chest revealed a mass in the right upper lobe of the lungs.\n            The mass is suspected to be malignant and is likely to be a tumor.\n            Further diagnostic tests, such as biopsy or CT scan of the mass, may be required to confirm the diagnosis.\n            Recommendations:\n            The patient is advised to consult with a medical specialist for a thorough evaluation of the mass.\n            If the tumor is malignant, further treatment, such as surgery or radiotherapy, may be recommended.\n            '''\n\n        &gt;&gt;&gt; results = anonymise(text, analyser=analyser, entities=[\"DATE_TIME\", \"PERSON\"], regex_recognizers=[\"POSTCODE\", \"NHS_NUMBER\"])\n        &gt;&gt;&gt; print(results)\n\n            Patient Name: &lt;PERSON&gt;\n            NHS Number: &lt;NHS_NUMBER&gt;\n            Address: &lt;POSTCODE&gt;\n            Date: &lt;DATE_TIME&gt;\n            Diagnostic Findings:\n            The CT scan of the patient's chest revealed a mass in the right upper lobe of the lungs.\n            The mass is suspected to be malignant and is likely to be a tumor.\n            Further diagnostic tests, such as biopsy or CT scan of the mass, may be required to confirm the diagnosis.\n            Recommendations:\n            The patient is advised to consult with a medical specialist for a thorough evaluation of the mass.\n            If the tumor is malignant, further treatment, such as surgery or radiotherapy, may be recommended.\n    \"\"\"\n    # Prepare\n    entities = [entities] if isinstance(entities, str) else entities if entities else []\n    regex_entities = (\n        build_regex_entity_recogniser_list(regex_entities=regex_entities)\n        if regex_entities\n        else []\n    )\n    allowed_entities = entities\n    allowed_regex_entities = [\n        regex_entity.entity_type for regex_entity in regex_entities\n    ]\n    entities = allowed_entities + allowed_regex_entities\n\n    # Check Analyser\n    if not analyser:\n        analyser = create_analyser(\n            model_path=model_path,\n            spacy_model=spacy_model,\n            language=language,\n            regex_entities=regex_entities,\n        )\n    else:\n        if rebuild_regex_recognisers:\n            rebuild_analyser_regex_recognisers(\n                analyser=analyser, regex_entities=regex_entities\n            )\n\n    # Analyse the text\n    initial_results = analyse(\n        text,\n        analyser,\n        entities=entities,\n        regex_entities=regex_entities,\n        mask_individual_words=mask_individual_words,\n        text_separator=text_separator,\n        rebuild_regex_recognisers=False,\n        **kwargs,\n    )\n\n    # Create an OperatorConfig that randomly selects replacements from the replacement list\n    operator_config = None\n    if entities:\n        if replacement_lists:\n            operator_config = {}\n            for entity in entities:\n                if entity in replacement_lists:\n                    operator_config[entity] = OperatorConfig(\n                        \"replace\",\n                        {\"new_value\": random.choice(replacement_lists[entity])},\n                    )\n\n    # Anonymise the text\n    anonymiser = AnonymizerEngine()\n\n    # if-else is strictly required as the anonymize method modifies initial_results variable when called\n    if not mask_individual_words:\n        anonymized_result = anonymiser.anonymize(\n            text=text, analyzer_results=initial_results, operators=operator_config\n        )\n    else:\n        # this is essentially AnonymizerEngine.anonymize without merging adjacent entities of the same type\n        # some discussion around merging adjacent entities: https://github.com/microsoft/presidio/issues/1090\n        analyzer_results = anonymiser._remove_conflicts_and_get_text_manipulation_data(\n            initial_results, ConflictResolutionStrategy.MERGE_SIMILAR_OR_CONTAINED\n        )\n        operators = anonymiser._AnonymizerEngine__check_or_add_default_operator(\n            operator_config\n        )\n        anonymized_result = anonymiser._operate(\n            text, analyzer_results, operators, OperatorType.Anonymize\n        )\n\n    # TODO - could be managed by creating an Operatorconfig for \"PHONE_NUMBER\"\n    anonymised_text = anonymized_result.text.replace(\"PHONE_NUMBER\", \"NUMBER\")\n\n    return highlight_text(anonymised_text) if highlight else anonymised_text\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#regex_check_functions","title":"Regex Check Functions","text":""},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.regex_check_functions.is_nhs_number","title":"<code>is_nhs_number(nhs_number)</code>","text":"<p>Check if a given value is a valid NHS number.</p> <p>Parameters:</p> Name Type Description Default <code>nhs_number</code> <code>int | str</code> <p>The NHS number to be checked.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the given value is a valid NHS number, otherwise False.</p> Example <p>is_nhs_number(1234567890) True is_nhs_number(\"1234567890\") True is_nhs_number(\"1234567898\") True # (fails checksum) is_nhs_number(\"12345\") False # (fails length check)</p> Note <p>The NHS number is a 10-digit number used in the United Kingdom for healthcare identification. The last digit of the NHS number is a check digit calculated by a special modules 11 algorithm for validation.</p> Source code in <code>pteredactyl\\pteredactyl\\regex_check_functions.py</code> <pre><code>def is_nhs_number(nhs_number: str | int) -&gt; bool:\n    \"\"\"\n    Check if a given value is a valid NHS number.\n\n    Args:\n        nhs_number (int | str): The NHS number to be checked.\n        Should be a string containing only numbers, (use of spaces and hyphens is permitted and will be processed).\n\n    Returns:\n        bool: True if the given value is a valid NHS number, otherwise False.\n\n    Example:\n        &gt;&gt;&gt; is_nhs_number(1234567890)\n        True\n        &gt;&gt;&gt; is_nhs_number(\"1234567890\")\n        True\n        &gt;&gt;&gt; is_nhs_number(\"1234567898\")\n        True # (fails checksum)\n        &gt;&gt;&gt; is_nhs_number(\"12345\")\n        False # (fails length check)\n\n    Note:\n        The NHS number is a 10-digit number used in the United Kingdom for healthcare identification.\n        The last digit of the NHS number is a check digit calculated by a special modules 11 algorithm for validation.\n    \"\"\"\n\n    # Prepare NHS Number\n    nhs_number = (\n        str(nhs_number)\n        if isinstance(nhs_number, int)\n        else nhs_number.replace(\" \", \"\").replace(\"-\", \"\")\n    )\n\n    # Check Only Digits\n    if not nhs_number.isdigit():\n        return False\n\n    # Check Length\n    if len(nhs_number) != 10:\n        return False\n\n    # Check Checksum\n    total = 0\n    for i, digit in enumerate(nhs_number[0:-1]):\n        position = i + 1\n        multiplier = 11 - position\n        total += int(digit) * multiplier\n\n    checksum = 11 - (total % 11)\n    checksum = 0 if checksum == 11 else checksum\n    check_digit = int(nhs_number[-1])\n\n    if checksum != check_digit or checksum == 10:\n        return False\n\n    # All checks passed\n    else:\n        return True\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#regex_entities","title":"Regex Entities","text":""},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.regex_entities.build_pteredactyl_recogniser","title":"<code>build_pteredactyl_recogniser(entity_type, regex, check_function)</code>","text":"<p>Build a custom regex ptererecogniser for pteredactyl.</p> <p>Parameters:</p> Name Type Description Default <code>entity_type</code> <code>str</code> <p>The name of the entity to be recognised.</p> required <code>regex</code> <code>str or Pattern</code> <p>The regular expression to match the entity.</p> required <code>check_function</code> <code>Callable</code> <p>A function to check if the matched string is a valid entity. Should take a single argument (the matched string) and return a boolean.</p> required <p>Returns:</p> Name Type Description <code>PteredactylRecogniser</code> <code>PteredactylRecogniser</code> <p>A custom presidio EntityRecognizer object.</p> <p>Example:</p> <p>def check_soton_landline(input: str): ... cleaned = input.replace('-','').replace(' ','') ... return cleaned.startswith('0238')</p> <p>recogniser = build_pteredactyl_recogniser(entity_type='SOUTHAMPTON_LANDLINE', ...                                           regex=r'(?:\\d[\\s-]?){11}', ...                                           check_function=check_soton_landline)</p> Source code in <code>pteredactyl\\pteredactyl\\regex_entities.py</code> <pre><code>def build_pteredactyl_recogniser(\n    entity_type: str,\n    regex: str | re.Pattern,\n    check_function: Callable[..., bool] | None,\n) -&gt; PteredactylRecogniser:\n    \"\"\"\n    Build a custom regex ptererecogniser for pteredactyl.\n\n    Args:\n        entity_type (str): The name of the entity to be recognised.\n        regex (str or re.Pattern): The regular expression to match the entity.\n        check_function (Callable, optional): A function to check if the matched string is a valid entity. Should take a single argument (the matched string) and return a boolean.\n\n    Returns:\n        PteredactylRecogniser: A custom presidio EntityRecognizer object.\n\n    Example:\n    &gt;&gt;&gt; def check_soton_landline(input: str):\n    ... cleaned = input.replace('-','').replace(' ','')\n    ... return cleaned.startswith('0238')\n\n\n    &gt;&gt;&gt; recogniser = build_pteredactyl_recogniser(entity_type='SOUTHAMPTON_LANDLINE',\n    ...                                           regex=r'(?:\\\\d[\\\\s-]?){11}',\n    ...                                           check_function=check_soton_landline)\n    \"\"\"\n\n    regex = re.compile(regex) if isinstance(regex, str) else regex\n    return PteredactylRecogniser(\n        entity_type=entity_type, regex=regex, check_function=check_function\n    )\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.regex_entities.build_regex_entity_recogniser_list","title":"<code>build_regex_entity_recogniser_list(regex_entities)</code>","text":"<p>Build a list of custom regex PteredactylRecognisers.</p> <p>Parameters:</p> Name Type Description Default <code>regex_entities</code> <code>list[str or PteredactylRecogniser]</code> <p>A list of PteredactylRecogniser objects or strings referencing pre-built PteredactylRecognisers.</p> required <p>Returns:</p> Type Description <code>list[PteredactylRecogniser]</code> <p>list[PteredactylRecogniser]: A list of custom presidio EntityRecognizer objects.</p> <p>Example:</p> <p>recognisers = build_regex_entity_recogniser_list(['NHS_NUMBER', ...                                                    'ENTITY_2', ...                                                    PteredactylRecogniser(entity_type='SOUTHAMPTON_LANDLINE', ...                                                                          regex=r'\\b((?:+44\\s?7\\d{3}|?)\\s?\\d{3}\\s?\\d{3}|?\\s?\\d{1,4}\\s?\\d{1,4})\\b', ...                                                                          check_function=check_so_landline ...                                                   ])</p> Source code in <code>pteredactyl\\pteredactyl\\regex_entities.py</code> <pre><code>def build_regex_entity_recogniser_list(\n    regex_entities: str | PteredactylRecogniser | Sequence[str | PteredactylRecogniser],\n) -&gt; list[PteredactylRecogniser]:\n    \"\"\"\n    Build a list of custom regex PteredactylRecognisers.\n\n    Args:\n        regex_entities (list[str or PteredactylRecogniser]): A list of PteredactylRecogniser objects or strings referencing pre-built PteredactylRecognisers.\n\n    Returns:\n        list[PteredactylRecogniser]: A list of custom presidio EntityRecognizer objects.\n\n    Example:\n    &gt;&gt;&gt; recognisers = build_regex_entity_recogniser_list(['NHS_NUMBER',\n    ...                                                    'ENTITY_2',\n    ...                                                    PteredactylRecogniser(entity_type='SOUTHAMPTON_LANDLINE',\n    ...                                                                          regex=r'\\\\b((?:\\\\+44\\\\s?7\\\\d{3}|\\\\(?07\\\\d{3}\\\\)?)\\\\s?\\\\d{3}\\\\s?\\\\d{3}|\\\\(?01\\\\d{1,4}\\\\)?\\\\s?\\\\d{1,4}\\\\s?\\\\d{1,4})\\\\b',\n    ...                                                                          check_function=check_so_landline\n    ...                                                   ])\n    \"\"\"\n\n    regex_entity_recognisers = []\n    if type(regex_entities) in (str, PteredactylRecogniser):\n        regex_entities = [regex_entities]\n\n    for regex_entity in regex_entities:\n        if isinstance(regex_entity, str):\n            regex_entity_recognisers.append(\n                fetch_pteredactyl_recogniser(entity_type=regex_entity)\n            )\n        else:\n            regex_entity_recognisers.append(regex_entity)\n\n    return regex_entity_recognisers\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.regex_entities.rebuild_analyser_regex_recognisers","title":"<code>rebuild_analyser_regex_recognisers(analyser, regex_entities)</code>","text":"<p>Rebuilds the analyser's regex recognisers with the supplied list of regex entities.</p> <p>Parameters:</p> Name Type Description Default <code>analyser</code> <code>AnalyzerEngine</code> <p>The analyser to rebuild.</p> required <code>regex_entities</code> <code>list[str or PteredactylRecogniser]</code> <p>The list of regex entities to use.</p> required <p>Returns:</p> Source code in <code>pteredactyl\\pteredactyl\\regex_entities.py</code> <pre><code>def rebuild_analyser_regex_recognisers(\n    analyser: AnalyzerEngine, regex_entities: Sequence[str | PteredactylRecogniser]\n) -&gt; None:\n    \"\"\"\n    Rebuilds the analyser's regex recognisers with the supplied list of regex entities.\n\n    Args:\n        analyser (AnalyzerEngine): The analyser to rebuild.\n        regex_entities (list[str or PteredactylRecogniser]): The list of regex entities to use.\n\n    Returns:\n    \"\"\"\n\n    analyser.registry.remove_recognizer(PTEREDACTYL_RECOGNISER_NAME)\n    pteredactyl_recognisers = build_regex_entity_recogniser_list(regex_entities)\n    for recogniser in pteredactyl_recognisers:\n        analyser.registry.add_recognizer(recogniser)\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#support","title":"Support","text":""},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.support.find_substring_positions","title":"<code>find_substring_positions(s, sep=' ')</code>","text":"<p>Finds the starting and ending indexes of substrings in the input string <code>s</code>.     The substrings are determined by splitting <code>s</code> at separator.</p> <pre><code>Args:\n    s (str): The input string containing substrings separated by newlines.\n    sept (str): Separator for substrings.\n\nReturns:\n    list[tuple[int, int]]: A list of tuples, each containing the start and end index of a substring.\n\nExamples:\n&gt;&gt;&gt; s = \"abc\n</code></pre> <p>def\"     &gt;&gt;&gt; positions = find_substring_positions(s, sep=\" \")     &gt;&gt;&gt; print(\"Replacement Positions: \", positions)     Replacement Positions: [(0, 3), (4, 7)]</p> Source code in <code>pteredactyl\\pteredactyl\\support.py</code> <pre><code>def find_substring_positions(s: str, sep: str = \" \") -&gt; list[tuple[int, int]]:\n    \"\"\"Finds the starting and ending indexes of substrings in the input string `s`.\n    The substrings are determined by splitting `s` at separator.\n\n    Args:\n        s (str): The input string containing substrings separated by newlines.\n        sept (str): Separator for substrings.\n\n    Returns:\n        list[tuple[int, int]]: A list of tuples, each containing the start and end index of a substring.\n\n    Examples:\n    &gt;&gt;&gt; s = \"abc\\ndef\"\n    &gt;&gt;&gt; positions = find_substring_positions(s, sep=\"\\n\")\n    &gt;&gt;&gt; print(\"Replacement Positions: \", positions)\n    Replacement Positions: [(0, 3), (4, 7)]\n    \"\"\"\n    replacement_positions = []\n\n    for substring in s.split(sep):\n        for match in re.finditer(re.escape(substring), s):\n            start, end = match.span()\n            replacement_positions.append((start, end))\n\n    return replacement_positions\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.support.load_nlp_configuration","title":"<code>load_nlp_configuration(language, spacy_model)</code>","text":"<p>Loads NLP configuration for spacy model</p> <p>Parameters:</p> Name Type Description Default <code>language</code> <code>str</code> <p>Model language (e.g. en)</p> required <code>spacy_model</code> <code>str</code> <p>Name of spacy model (e.g. en_core_web_sm)</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>configuration dictionary that can be passed to create an NlpEngineProvider</p> Source code in <code>pteredactyl\\pteredactyl\\support.py</code> <pre><code>def load_nlp_configuration(language: str, spacy_model: str) -&gt; dict[str, Any]:\n    \"\"\"Loads NLP configuration for spacy model\n\n    Args:\n        language (str): Model language (e.g. en)\n        spacy_model (str): Name of spacy model (e.g. en_core_web_sm)\n\n    Returns:\n        dict: configuration dictionary that can be passed to create an NlpEngineProvider\n    \"\"\"\n    return {\n        \"nlp_engine_name\": \"spacy\",\n        \"models\": [\n            {\n                \"lang_code\": language,\n                \"model_name\": spacy_model,\n            }\n        ],\n        \"ner_model_configuration\": {\"labels_to_ignore\": SPACY_LABELS_TO_IGNORE},\n    }\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.support.load_nlp_engine","title":"<code>load_nlp_engine(presidio_logger, nlp_configuration)</code>","text":"<p>Loads a NlpEngineProvider by creating a new engine.</p> <p>Parameters:</p> Name Type Description Default <code>presidio_logger</code> <code>Logger</code> <p>Logger object to set and restore logging level.</p> required <code>nlp_configuration</code> <code>dict</code> <p>Configuration for the NlpEngineProvider.</p> required <p>Returns:</p> Name Type Description <code>NlpEngineProvider</code> <code>NlpEngine</code> <p>The loaded engine.</p> Source code in <code>pteredactyl\\pteredactyl\\support.py</code> <pre><code>def load_nlp_engine(\n    presidio_logger: Logger, nlp_configuration: dict[str, Any]\n) -&gt; NlpEngine:\n    \"\"\"\n    Loads a NlpEngineProvider by creating a new engine.\n\n    Args:\n        presidio_logger (Logger): Logger object to set and restore logging level.\n        nlp_configuration (dict): Configuration for the NlpEngineProvider.\n\n    Returns:\n        NlpEngineProvider: The loaded engine.\n    \"\"\"\n    log_level = presidio_logger.level\n    presidio_logger.setLevel(\"ERROR\")\n    nlp_engine = NlpEngineProvider(nlp_configuration=nlp_configuration).create_engine()\n    presidio_logger.setLevel(log_level)\n\n    return nlp_engine\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.support.load_registry","title":"<code>load_registry(transformers_recogniser, regex_entities)</code>","text":"<p>Creates an AnalyzerEngine.registry by combining a TransformersRecogniser with a list of custom PteredactylRecognisers</p> <p>Parameters:</p> Name Type Description Default <code>transformers_recogniser</code> <code>TransformersRecogniser</code> <p>Custom transformers recogniser</p> required <code>regex_entities</code> <code>list[str | PteredactylRecogniser]</code> <p>Named regex entities to generate PtereractylRecognisers, or custom PtereractylRecognisers</p> required <p>Returns:</p> Name Type Description <code>RecognizerRegistry</code> <code>RecognizerRegistry</code> <p>registry of Recognisers for an AnalyzerEngine</p> Source code in <code>pteredactyl\\pteredactyl\\support.py</code> <pre><code>def load_registry(\n    transformers_recogniser: TransformersRecogniser,\n    regex_entities: Sequence[str | PteredactylRecogniser],\n) -&gt; RecognizerRegistry:\n    \"\"\"Creates an AnalyzerEngine.registry by combining a TransformersRecogniser with a list of custom PteredactylRecognisers\n\n    Args:\n        transformers_recogniser (TransformersRecogniser): Custom transformers recogniser\n        regex_entities (list[str | PteredactylRecogniser]): Named regex entities to generate PtereractylRecognisers, or custom PtereractylRecognisers\n\n    Returns:\n        RecognizerRegistry: registry of Recognisers for an AnalyzerEngine\n    \"\"\"\n    registry = RecognizerRegistry()\n    # registry.load_predefined_recognizers() # Presidio default recognizers - largely not needed\n    registry.add_recognizer(transformers_recogniser)\n    registry.remove_recognizer(\"SpacyRecognizer\")\n\n    if regex_entities:\n        for entity in regex_entities:\n            if isinstance(entity, str):\n                recogniser = fetch_pteredactyl_recogniser(entity_type=entity)\n            elif isinstance(entity, PteredactylRecogniser):\n                recogniser = entity\n            registry.add_recognizer(recogniser)\n\n    return registry\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.support.load_spacy_model","title":"<code>load_spacy_model(spacy_model)</code>","text":"<p>Downloads spacy model if not already installed</p> <p>Parameters:</p> Name Type Description Default <code>spacy_model</code> <code>str</code> <p>Name of spacy model</p> required Source code in <code>pteredactyl\\pteredactyl\\support.py</code> <pre><code>def load_spacy_model(spacy_model: str) -&gt; None:\n    \"\"\"Downloads spacy model if not already installed\n\n    Args:\n        spacy_model (str): Name of spacy model\n    \"\"\"\n    if not spacy.util.is_package(spacy_model):\n        print(f\"Downloading model '{spacy_model}' for the first time, please wait...\")\n        spacy.cli.download(spacy_model)\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.support.load_transformers_recognizer","title":"<code>load_transformers_recognizer(model_path)</code>","text":"<p>Loads transformers recognizer with the specified model path</p> <p>Parameters:</p> Name Type Description Default <code>model_path</code> <code>str</code> <p>Path to the transformer model</p> required <p>Returns:</p> Name Type Description <code>TransformersRecogniser</code> <code>TransformersRecogniser</code> <p>Loaded transformers recognizer</p> Source code in <code>pteredactyl\\pteredactyl\\support.py</code> <pre><code>def load_transformers_recognizer(model_path: str) -&gt; TransformersRecogniser:\n    \"\"\"Loads transformers recognizer with the specified model path\n\n    Args:\n        model_path (str): Path to the transformer model\n\n    Returns:\n        TransformersRecogniser: Loaded transformers recognizer\n    \"\"\"\n    print(f\"Loading transformers recognizer with model path: {model_path}\")\n    config = _get_config(model_path=model_path)\n    transformers_recognizer = TransformersRecogniser(model_path=model_path)\n    transformers_recognizer.load_transformer(**config)\n    print(f\"Model {model_path} loaded successfully\")\n    return transformers_recognizer\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.support.return_allowed_results","title":"<code>return_allowed_results(initial_results, allowed_entities, allowed_regex_entities)</code>","text":"<p>Checks list of RecognizerResults for allowed entities returns a list of allowed results.</p> <p>Parameters:</p> Name Type Description Default <code>initial_results</code> <code>list[RecognizerResult]</code> <p>The list of RecognizerResults to filter.</p> required <code>allowed_entities</code> <code>list[str]</code> <p>The list of entity types to allow.</p> required <code>allowed_regex_entities</code> <code>list[str]</code> <p>The list of regex entity types to allow.</p> required <p>Returns:</p> Type Description <code>list[RecognizerResult]</code> <p>list[RecognizerResult]: The filtered list of RecognizerResults.</p> Source code in <code>pteredactyl\\pteredactyl\\support.py</code> <pre><code>def return_allowed_results(\n    initial_results: list[RecognizerResult],\n    allowed_entities: list[str],\n    allowed_regex_entities: list[str],\n) -&gt; list[RecognizerResult]:\n    \"\"\"\n    Checks list of RecognizerResults for allowed entities returns a list of allowed results.\n\n    Args:\n        initial_results (list[RecognizerResult]): The list of RecognizerResults to filter.\n        allowed_entities (list[str]): The list of entity types to allow.\n        allowed_regex_entities (list[str]): The list of regex entity types to allow.\n\n    Returns:\n        list[RecognizerResult]: The filtered list of RecognizerResults.\n    \"\"\"\n    results = []\n    for result in initial_results:\n        recogniser = result.recognition_metadata[\"recognizer_name\"]\n        entity_type = result.entity_type\n\n        if recogniser == PTEREDACTYL_RECOGNISER_NAME:\n            if entity_type in allowed_regex_entities:\n                results.append(result)\n        else:\n            if entity_type in allowed_entities:\n                results.append(result)\n\n    return results\n</code></pre>"},{"location":"Python_Module/mkdocstrings/#pteredactyl.pteredactyl.support.split_results_into_individual_words","title":"<code>split_results_into_individual_words(text, results, text_separator=' ')</code>","text":"<p>Splits identified RecognizerResults into individual words. For example, Jane Smith becomes  , rather than . <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text that was analyzed.</p> required <code>results</code> <code>list[RecognizerResult]</code> <p>The results of the analysis.</p> required <code>text_separator</code> <code>str</code> <p>The separator used to split the text into individual words.</p> <code>' '</code> <p>Returns:</p> Type Description <code>list[RecognizerResult]</code> <p>list[RecognizerResult]: A list of RecognizerResults, each representing an individual word.</p> Source code in <code>pteredactyl\\pteredactyl\\support.py</code> <pre><code>def split_results_into_individual_words(\n    text: str, results: list[RecognizerResult], text_separator: str = \" \"\n) -&gt; list[RecognizerResult]:\n    \"\"\"\n    Splits identified RecognizerResults into individual words. For example, Jane Smith becomes &lt;PERSON&gt; &lt;PERSON&gt;, rather than &lt;PERSON&gt;.\n\n    Args:\n        text (str): The text that was analyzed.\n        results (list[RecognizerResult]): The results of the analysis.\n        text_separator (str): The separator used to split the text into individual words.\n\n    Returns:\n        list[RecognizerResult]: A list of RecognizerResults, each representing an individual word.\n    \"\"\"\n    masked_individual_words_results = []\n    for result in results:\n        substrings = text[result.start : result.end]\n        for substring_position in find_substring_positions(\n            substrings, sep=text_separator\n        ):\n            offset = result.start\n            masked_individual_words_results.append(\n                RecognizerResult(\n                    entity_type=result.entity_type,\n                    start=substring_position[0] + offset,\n                    end=substring_position[1] + offset,\n                    score=result.score,\n                    analysis_explanation=result.analysis_explanation,\n                    recognition_metadata=result.recognition_metadata,\n                )\n            )\n    return masked_individual_words_results\n</code></pre>"},{"location":"Python_Module/passing_custom_regex_entities/","title":"Passing Custom Regex Entities","text":"<p>We can include custom regex and check functions in our analysis/redaction, too:</p> <pre><code>import pteredactyl as pt\nfrom pteredactyl import build_pteredactyl_recogniser\n\n# Create an analyser\nanalyser = pt.create_analyser()\n\n# Build a custom regex recogniser\ndef check_soton_landline(input: str):\n    cleaned = input.replace('-','').replace(' ','')\n    return cleaned.startswith('0238')\n\n\nsoton_landline_recogniser = build_pteredactyl_recogniser(entity_type = 'SOUTHAMPTON_LANDLINE',\n                                           regex = r'(?:\\d[\\s-]?){11}',\n                                           check_function = check_soton_landline)\n\n# Use the analyser to redact some text\ntext = \"The patient's name is Steven Johnson. His NHS Number is 0123456789 and postcode is SO16 2HQ. He was diagnosed with Stevens Johnson Syndrome on the 1st of January 2024. He can be contacted at 02380 111111\"\nredacted_text = pt.anonymise(text=text, analyser=analyser, highlight=True, entities=\"PERSON\", regex_entities=[\"NHS_NUMBER\", \"POSTCODE\", soton_landline_recogniser])\n\nprint(redacted_text)\n</code></pre> <pre><code>The patient's name is &lt;PERSON&gt;. His NHS Number is &lt;NHS_NUMBER&gt; and postcode is &lt;POSTCODE&gt;. He was diagnosed with Stevens Johnson Syndrome on the 1st of January 2024. He can be contacted at &lt;SOUTHAMPTON_LANDLINE&gt;\n</code></pre>"},{"location":"Python_Module/quickstart/","title":"Quickstart","text":"<p>Here is a hello world quickstart deployment to get anyone going with Pteredactyl</p> <pre><code># Simple anonymisation\nimport pteredactyl as pt\ntext = \"The patient's name is Steven Johnson. His NHS Number is 0123456789 and postcode is SO16 2HQ. He has been diagnosed with Stevens Johnson Syndrome\"\n\nanonymised_text = pt.anonymise(text)\n</code></pre> <p>You can also configure the package by passing different parameters:</p> <ul> <li><code>entities</code>: List of entities to anonymise.</li> <li><code>replacement_lists</code>: Custom replacement values for each entity.</li> <li><code>highlight</code>: Set to <code>True</code> to highlight anonymised parts in the output.</li> </ul> <pre><code># Anonymisation for specific entities\nentities = [\"LOCATION\", \"PERSON\"]\nanonymised_text = pt.anonymise(text, entities=entities)\n\n# Hide in plain site by supplying a dictionary of entities: potential replacements\nreplacement_lists = {\n    \"PERSON\": [\"Alice Smith\", \"Bob Johnson\", \"Carol Davis\"],\n    \"LOCATION\": [\"Los Angeles\", \"Chicago\", \"Houston\"]\n}\nanonymised_text = pt.anonymise(text, replacement_lists=replacement_lists)\n</code></pre>"},{"location":"Python_Module/reusing_an_analyser/","title":"Reusing An Analyser","text":"<p>When analysing or anonymising multiple pieces of text or DataFrames in the same way, it is highly recommended to create and reuse a single analyser (presidio AnalyzerEngine). While each high-level PteRedactyl function will spin up an analyser if one is not provided, an analyser can be created and then passed, to reuse it.</p> <p>Example Usage:</p> <pre><code>import pteredactyl as pt\n\n# Create an analyser\nanalyser = pt.create_analyser()\n\n# Use the analyser to redact some text\ntext = \"The patient's name is Steven Johnson. His NHS Number is 0123456789 and postcode is SO16 2HQ. He has been diagnosed with Stevens Johnson Syndrome\"\nredacted_text = pt.anonymise(text=text, analyser=analyser, highlight=True)\n\nprint(redacted_text)\n</code></pre>"},{"location":"Python_Module/selecting_entities_to_redact/","title":"Selecting Entities To Redact","text":"<p>We can select specific NER or regex entities to analyse/redact by feeding in these arguments. When empty, PteRedactyl will redact according to a predefined list, which can be checked as follows:</p> <pre><code>import pteredactyl as pt\npt.show_defaults()\n</code></pre> <p>Let's try redacting only specific entities:</p> <pre><code>import pteredactyl as pt\n\n# Create an analyser\nanalyser = pt.create_analyser()\n\n# Use the analyser to redact some text\ntext = \"The patient's name is Steven Johnson. His NHS Number is 0123456789 and postcode is SO16 2HQ. He was diagnosed with Stevens Johnson Syndrome on the 1st of January 2024.\"\nredacted_text = pt.anonymise(text=text, analyser=analyser, highlight=True)\n\nprint(redacted_text)\n\n# Redact specific entities - keeping the date\ntext = \"The patient's name is Steven Johnson. His NHS Number is 0123456789 and postcode is SO16 2HQ. He was diagnosed with Stevens Johnson Syndrome on the 1st of January 2024.\"\nredacted_text = pt.anonymise(text=text, analyser=analyser, highlight=True, entities=\"PERSON\", regex_entities=[\"NHS_NUMBER\", \"POSTCODE\"])\n\nprint(redacted_text)\n</code></pre>"},{"location":"Webapp-API/developing-contributing/","title":"Developing/Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"Webapp-API/developing-contributing/#types_of_contributions","title":"Types of Contributions","text":""},{"location":"Webapp-API/developing-contributing/#report_bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/SETT-Centre-Data-and-AI/PteRedactyl/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"Webapp-API/developing-contributing/#fix_bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"Webapp-API/developing-contributing/#implement_features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"Webapp-API/developing-contributing/#submit_feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/SETT-Centre-Data-and-AI/PteRedactyl/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> </ul>"},{"location":"Webapp-API/developing-contributing/#get_started","title":"Get Started","text":"<p>Ready to contribute? Here's how to set up <code>pteredactyl</code> for local development.</p> <ol> <li>Fork the <code>pteredactyl</code> repo on GitHub.</li> <li> <p>Clone your fork locally:</p> <p><code>bash git clone git@github.com:your_name_here/pteredactyl.git</code></p> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have poetry installed, this is how you set up your fork for local development:</p> <p><code>bash poetry shell poetry install</code></p> </li> <li> <p>Create a branch for local development::</p> <p><code>bash git checkout -b name-of-your-bugfix-or-feature</code></p> </li> </ol> <p>Now you can make your changes locally.</p> <ol> <li> <p>When you're done making changes, check that your changes pass the pre-commit hooks. To set this up call the following from your git repository:</p> <p><code>bash pre-commit install</code></p> </li> <li> <p>Commit your changes and push your branch to GitHub::</p> <p><code>bash git add . git commit -m \"Your detailed description of your changes.\" git push</code> or <code>bash git add . cz commit git push</code></p> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"Webapp-API/developing-contributing/#pull_request_guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.rst.</li> <li>The pull request should work for Python &gt;3.10</li> </ol>"},{"location":"Webapp-API/developing-contributing/#tips","title":"Tips","text":"<p>To run a subset of tests navigate to the tests folder and call a test::</p> <pre><code>python test_api.py\n</code></pre>"},{"location":"Webapp-API/developing-contributing/#deploying","title":"Deploying","text":"<p>To build a docker image deployment with the web-app / API version you can use the following in your command line:</p> <pre><code>docker build -t pteredactyl:latest .\ndocker run -d -p 7860:7860 --name pteredactyl-app pteredactyl:latest\n</code></pre>"},{"location":"Webapp-API/docker/","title":"Docker","text":"<p>The app can easily be deployed using docker with a bridge network binding to port 7860. The image can be built and deployed from source as follows:</p> <pre><code>docker build -t pteredactyl:latest .\ndocker run -d -p 7860:7860 --name pteredactyl-app pteredactyl:latest\n</code></pre>"},{"location":"Webapp-API/docker/#docker_hub","title":"Docker Hub","text":"<p>The webapp can also be deployed directly from Docker Hub to any cloud service container.</p>"},{"location":"Webapp-API/gradio/","title":"Gradio","text":"<p>The source code for the web app and API can be found here Pteredactyl_Gradio_Web_App.</p>"},{"location":"Webapp-API/gradio/#deploying_gradio_app_from_source","title":"Deploying Gradio App from source","text":"<p>To deploy a gradio app is fairly simple. First clone the git repository:</p> <pre><code>git clone {git repo}\n</code></pre> <p>Then navigate into the src/pteredactyl_webapp directory and making sure poetry is installed first set up the poetry venv as follows:</p> <pre><code>poetry shell\npoetry install\n</code></pre> <p>Then to run the app you call</p> <pre><code>python app.py\n</code></pre> <p>and the app will run. If you want to see the gradio-deployed production version you can play with it here:</p> <p>This webapp is already available online as a gradio app on Huggingface: Huggingface Gradio App.</p>"},{"location":"Webapp-API/introduction/","title":"Introduction","text":"<p>We have deployed this app from source and as a module so that developers can get their hands on it.</p> <p>However, we also recognise that most NHS and healthcare institions internationally do not have time for this and just want to deploy on prem / in the cloud to test the API.</p> <p>For this reason we have deployed Peteredactyl as both source, a module and as a Gradio web-app with API. We picked Gradio because it interfaces really well with Huggingface, is lightweight and is much easier to maintain.</p>"},{"location":"Webapp-API/introduction/#need_help","title":"Need Help?","text":"<p>If you need further help reach out to us on our Github page or raise an issue.</p>"}]}